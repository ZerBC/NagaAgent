import logging,os,asyncio # æ—¥å¿—ä¸ç³»ç»Ÿ
from datetime import datetime # æ—¶é—´
from config import LOG_DIR, DEEPSEEK_API_KEY, DEEPSEEK_MODEL, TEMPERATURE, MAX_TOKENS, get_current_datetime, DEEPSEEK_BASE_URL, NAGA_SYSTEM_PROMPT, VOICE_ENABLED, GRAG_ENABLED # é…ç½®
from mcpserver.mcp_manager import get_mcp_manager, remove_tools_filter, HandoffInputData # å¤šåŠŸèƒ½ç®¡ç†
from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX # handoffæç¤ºè¯
from mcpserver.agent_playwright_master import PlaywrightAgent, extract_url # å¯¼å…¥æµè§ˆå™¨ç›¸å…³ç±»
from openai import OpenAI,AsyncOpenAI # LLM
import difflib # æ¨¡ç³ŠåŒ¹é…
import sys,json,traceback
import time # æ—¶é—´æˆ³æ‰“å°
from mcpserver.mcp_registry import register_all_handoffs # å¯¼å…¥æ‰¹é‡æ³¨å†Œæ–¹æ³•
from voice.tts_handler import generate_speech, get_models, get_voices # TTSåŠŸèƒ½
import config
import asyncio
import json
import websockets 
import re # æ·»åŠ reæ¨¡å—å¯¼å…¥
from typing import List, Dict # ä¿®å¤Listæœªå¯¼å…¥
from thinking import TreeThinkingEngine # æ ‘çŠ¶æ€è€ƒå¼•æ“
from thinking.config import COMPLEX_KEYWORDS # å¤æ‚å…³é”®è¯

# GRAGè®°å¿†ç³»ç»Ÿå¯¼å…¥
if GRAG_ENABLED:
    try:
        from summer_memory.memory_manager import memory_manager
        logger = logging.getLogger("NagaConversation")
        logger.info("å¤å›­è®°å¿†ç³»ç»Ÿå·²åŠ è½½")
    except Exception as e:
        logger = logging.getLogger("NagaConversation")
        logger.error(f"å¤å›­è®°å¿†ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")
        memory_manager = None
else:
    memory_manager = None

now=lambda:time.strftime('%H:%M:%S:')+str(int(time.time()*1000)%10000) # å½“å‰æ—¶é—´
_builtin_print=print
print=lambda *a,**k:sys.stderr.write('[print] '+(' '.join(map(str,a)))+'\n')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger("NagaConversation")

_MCP_HANDOFF_REGISTERED=False

class NagaConversation: # å¯¹è¯ä¸»ç±»
    def __init__(self):
        self.mcp = get_mcp_manager()
        self.messages = []
        self.dev_mode = False
        self.client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL.rstrip('/') + '/')
        self.async_client = AsyncOpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL.rstrip('/') + '/')
        
        # åˆå§‹åŒ–GRAGè®°å¿†ç³»ç»Ÿ
        self.memory_manager = memory_manager
        if self.memory_manager:
            logger.info("å¤å›­è®°å¿†ç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # é›†æˆæ ‘çŠ¶æ€è€ƒç³»ç»Ÿ
        try:
            self.tree_thinking = TreeThinkingEngine(api_client=self, memory_manager=self.memory_manager)
            logger.info("æ ‘çŠ¶å¤–ç½®æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"æ ‘çŠ¶æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.tree_thinking = None
        
        global _MCP_HANDOFF_REGISTERED
        if not _MCP_HANDOFF_REGISTERED:
            try:
                logger.info("å¼€å§‹æ³¨å†Œæ‰€æœ‰Agent handoffå¤„ç†å™¨...")
                register_all_handoffs(self.mcp)  # ä¸€é”®æ³¨å†Œæ‰€æœ‰Agent
                logger.info("æˆåŠŸæ³¨å†Œæ‰€æœ‰Agent handoffå¤„ç†å™¨")
                _MCP_HANDOFF_REGISTERED = True
            except Exception as e:
                logger.error(f"æ³¨å†ŒAgent handoffå¤„ç†å™¨å¤±è´¥: {e}")
                traceback.print_exc(file=sys.stderr)

    async def _init_websocket(self):
        """åˆå§‹åŒ–WebSocketç®¡ç†å™¨"""
        try:
            await self.mcp.initialize_websocket(host='127.0.0.1', port=8081)
            logger.info("WebSocketç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"WebSocketç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

    def save_log(self, u, a):  # ä¿å­˜å¯¹è¯æ—¥å¿—
        if self.dev_mode:
            return  # å¼€å‘è€…æ¨¡å¼ä¸å†™æ—¥å¿—
        d = datetime.now().strftime('%Y-%m-%d')
        t = datetime.now().strftime('%H:%M:%S')
        f = os.path.join(LOG_DIR, f'{d}.txt')
        with open(f, 'a', encoding='utf-8') as w:
            w.write(f'-'*50 + f'\næ—¶é—´: {d} {t}\nç”¨æˆ·: {u}\nå¨œè¿¦: {a}\n\n')

    async def _call_llm(self, messages: List[Dict]) -> Dict:
        """è°ƒç”¨LLM API"""
        resp = await self.async_client.chat.completions.create(
            model=DEEPSEEK_MODEL, 
            messages=messages, 
            temperature=TEMPERATURE, 
            max_tokens=MAX_TOKENS, 
            stream=False  # å·¥å…·è°ƒç”¨å¾ªç¯ä¸­ä¸ä½¿ç”¨æµå¼
        )
        return {
            'content': resp.choices[0].message.content,
            'status': 'success'
        }

    # å·¥å…·è°ƒç”¨å¾ªç¯ç›¸å…³æ–¹æ³•
    def _parse_tool_calls(self, content: str) -> list:
        """è§£æTOOL_REQUESTæ ¼å¼çš„å·¥å…·è°ƒç”¨"""
        tool_calls = []
        tool_request_start = "<<<[TOOL_REQUEST]>>>"
        tool_request_end = "<<<[END_TOOL_REQUEST]>>>"
        start_index = 0
        while True:
            start_pos = content.find(tool_request_start, start_index)
            if start_pos == -1:
                break
            end_pos = content.find(tool_request_end, start_pos)
            if end_pos == -1:
                start_index = start_pos + len(tool_request_start)
                continue
            tool_content = content[start_pos + len(tool_request_start):end_pos].strip()
            tool_name = None
            tool_args = {}
            param_pattern = r'(\w+)\s*:\s*ã€Œå§‹ã€([\s\S]*?)ã€Œæœ«ã€'
            for match in re.finditer(param_pattern, tool_content):
                key = match.group(1)
                value = match.group(2).strip()
                if key == 'tool_name':
                    tool_name = value
                else:
                    tool_args[key] = value
            if tool_name:
                tool_calls.append({'name': tool_name, 'args': tool_args})
            start_index = end_pos + len(tool_request_end)
        return tool_calls

    async def _execute_tool_calls(self, tool_calls: list) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        results = []
        for tool_call in tool_calls:
            try:
                result = await self.mcp.handoff(
                    service_name=tool_call['name'],
                    task=tool_call['args']
                )
                results.append(f"æ¥è‡ªå·¥å…· \"{tool_call['name']}\" çš„ç»“æœ:\n{result}")
            except Exception as e:
                error_result = f"æ‰§è¡Œå·¥å…· {tool_call['name']} æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
                results.append(error_result)
        return "\n\n---\n\n".join(results)

    async def handle_tool_call_loop(self, messages: List[Dict], is_streaming: bool = False) -> Dict:
        """å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯"""
        recursion_depth = 0
        max_recursion = int(os.getenv('MaxhandoffLoopStream', '5')) if is_streaming else int(os.getenv('MaxhandoffLoopNonStream', '5'))
        current_messages = messages.copy()
        current_ai_content = ''
        while recursion_depth < max_recursion:
            try:
                resp = await self._call_llm(current_messages)
                current_ai_content = resp.get('content', '')
                tool_calls = self._parse_tool_calls(current_ai_content)
                if not tool_calls:
                    break
                tool_results = await self._execute_tool_calls(tool_calls)
                current_messages.append({'role': 'assistant', 'content': current_ai_content})
                current_messages.append({'role': 'user', 'content': tool_results})
                recursion_depth += 1
            except Exception as e:
                print(f"å·¥å…·è°ƒç”¨å¾ªç¯é”™è¯¯: {e}")
                break
        return {
            'content': current_ai_content,
            'recursion_depth': recursion_depth,
            'messages': current_messages
        }

    def handle_llm_response(self, a, mcp):
        # åªä¿ç•™æ™®é€šæ–‡æœ¬æµå¼è¾“å‡ºé€»è¾‘ #
        async def text_stream():
            for line in a.splitlines():
                yield ("å¨œè¿¦", line)
        return text_stream()

    async def process(self, u, is_voice_input=False):  # æ·»åŠ is_voice_inputå‚æ•°
        import json  # ä¿è¯jsonåœ¨æœ¬åœ°ä½œç”¨åŸŸå¯ç”¨
        try:
            # å¼€å‘è€…æ¨¡å¼ä¼˜å…ˆåˆ¤æ–­
            if u.strip() == "#devmode":
                self.dev_mode = True
                yield ("å¨œè¿¦", "å·²è¿›å…¥å¼€å‘è€…æ¨¡å¼")
                return

            # åªåœ¨è¯­éŸ³è¾“å…¥æ—¶æ˜¾ç¤ºå¤„ç†æç¤º
            if is_voice_input:
                print(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥ï¼š{now()}")  # è¯­éŸ³è½¬æ–‡æœ¬ç»“æŸï¼Œå¼€å§‹å¤„ç†
            
            # GRAGè®°å¿†æŸ¥è¯¢
            memory_context = ""
            if self.memory_manager:
                try:
                    memory_result = await self.memory_manager.query_memory(u)
                    if memory_result:
                        memory_context = f"\n[è®°å¿†æ£€ç´¢ç»“æœ]: {memory_result}\n"
                        logger.info("ä»GRAGè®°å¿†ä¸­æ£€ç´¢åˆ°ç›¸å…³ä¿¡æ¯")
                except Exception as e:
                    logger.error(f"GRAGè®°å¿†æŸ¥è¯¢å¤±è´¥: {e}")
            
            # æ·»åŠ handoffæç¤ºè¯
            system_prompt = f"{RECOMMENDED_PROMPT_PREFIX}\n{NAGA_SYSTEM_PROMPT}"
            sysmsg = {"role": "system", "content": system_prompt.format(available_mcp_services=self.mcp.format_available_services())}  # ç›´æ¥ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯
            msgs = [sysmsg] if sysmsg else []
            msgs += self.messages[-20:] + [{"role": "user", "content": u}]

            print(f"GTPè¯·æ±‚å‘é€ï¼š{now()}")  # AIè¯·æ±‚å‰
            
            # æ ‘çŠ¶æ€è€ƒç³»ç»Ÿæ§åˆ¶æŒ‡ä»¤
            if u.strip().startswith("#tree"):
                if self.tree_thinking is None:
                    yield ("å¨œè¿¦", "æ ‘çŠ¶æ€è€ƒç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨è¯¥åŠŸèƒ½");return
                command = u.strip().split()
                if len(command) == 2:
                    if command[1] == "on":
                        self.tree_thinking.enable_tree_thinking(True)
                        yield ("å¨œè¿¦", "ğŸŒ³ æ ‘çŠ¶å¤–ç½®æ€è€ƒç³»ç»Ÿå·²å¯ç”¨");return
                    elif command[1] == "off":
                        self.tree_thinking.enable_tree_thinking(False)
                        yield ("å¨œè¿¦", "æ ‘çŠ¶æ€è€ƒç³»ç»Ÿå·²ç¦ç”¨ï¼Œæ¢å¤æ™®é€šå¯¹è¯æ¨¡å¼");return
                    elif command[1] == "status":
                        status = self.tree_thinking.get_system_status()
                        enabled_status = "å¯ç”¨" if status["enabled"] else "ç¦ç”¨"
                        yield ("å¨œè¿¦", f"ğŸŒ³ æ ‘çŠ¶æ€è€ƒç³»ç»ŸçŠ¶æ€ï¼š{enabled_status}\nå½“å‰ä¼šè¯ï¼š{status['current_session']}\nå†å²ä¼šè¯æ•°ï¼š{status['total_sessions']}");return
                yield ("å¨œè¿¦", "ç”¨æ³•ï¼š#tree on/off/status");return
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨è§¦å‘æ ‘çŠ¶æ€è€ƒ
            tree_thinking_enabled = False
            if hasattr(self, 'tree_thinking') and self.tree_thinking and getattr(self.tree_thinking, 'is_enabled', False):
                question_lower = u.lower()
                complex_count = sum(1 for keyword in COMPLEX_KEYWORDS if keyword in question_lower)
                if complex_count >= 1 or len(u) > 50:
                    tree_thinking_enabled = True
                    logger.info(f"æ£€æµ‹åˆ°å¤æ‚é—®é¢˜ï¼Œå¯ç”¨æ ‘çŠ¶æ€è€ƒ - å¤æ‚å…³é”®è¯: {complex_count}, é•¿åº¦: {len(u)}")
                    matched_keywords = [keyword for keyword in COMPLEX_KEYWORDS if keyword in question_lower]
                    logger.info(f"åŒ¹é…çš„å…³é”®è¯: {matched_keywords}")
                else:
                    logger.info(f"æœªè§¦å‘æ ‘çŠ¶æ€è€ƒ - å¤æ‚å…³é”®è¯: {complex_count}, é•¿åº¦: {len(u)}")

            # æ–°å¢ï¼šæ ‘çŠ¶æ€è€ƒå¤„ç†
            if tree_thinking_enabled:
                try:
                    yield ("å¨œè¿¦", "ğŸŒ³ æ£€æµ‹åˆ°å¤æ‚é—®é¢˜ï¼Œå¯åŠ¨æ ‘çŠ¶å¤–ç½®æ€è€ƒç³»ç»Ÿ...")
                    thinking_result = await self.tree_thinking.think_deeply(u)
                    if thinking_result and "answer" in thinking_result:
                        process_info = thinking_result.get("thinking_process", {})
                        difficulty = process_info.get("difficulty", {})
                        yield ("å¨œè¿¦", f"\nğŸ§  æ·±åº¦æ€è€ƒå®Œæˆï¼š")
                        yield ("å¨œè¿¦", f"â€¢ é—®é¢˜éš¾åº¦ï¼š{difficulty.get('difficulty', 'N/A')}/5")
                        yield ("å¨œè¿¦", f"â€¢ æ€è€ƒè·¯çº¿ï¼š{process_info.get('routes_generated', 0)}æ¡ â†’ {process_info.get('routes_selected', 0)}æ¡")
                        yield ("å¨œè¿¦", f"â€¢ å¤„ç†æ—¶é—´ï¼š{process_info.get('processing_time', 0):.2f}ç§’")
                        yield ("å¨œè¿¦", f"\n{thinking_result['answer']}")
                        final_answer = thinking_result['answer']
                        self.messages += [{"role": "user", "content": u}, {"role": "assistant", "content": final_answer}]
                        self.save_log(u, final_answer)

                        # GRAGè®°å¿†å­˜å‚¨ï¼ˆå¼€å‘è€…æ¨¡å¼ä¸å†™å…¥ï¼‰
                        if self.memory_manager and not self.dev_mode:
                            try:
                                await self.memory_manager.add_conversation_memory(u, final_answer)
                            except Exception as e:
                                logger.error(f"GRAGè®°å¿†å­˜å‚¨å¤±è´¥: {e}")
                        return
                    else:
                        yield ("å¨œè¿¦", "ğŸŒ³ æ ‘çŠ¶æ€è€ƒå¤„ç†å¼‚å¸¸ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼...")
                except Exception as e:
                    logger.error(f"æ ‘çŠ¶æ€è€ƒå¤„ç†å¤±è´¥: {e}")
                    yield ("å¨œè¿¦", f"ğŸŒ³ æ ‘çŠ¶æ€è€ƒç³»ç»Ÿå‡ºé”™ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼: {str(e)}")
                    
            # åªèµ°å·¥å…·è°ƒç”¨å¾ªç¯
            try:
                result = await self.handle_tool_call_loop(msgs, is_streaming=True)
                final_content = result['content']
                recursion_depth = result['recursion_depth']
                
                if recursion_depth > 0:
                    print(f"å·¥å…·è°ƒç”¨å¾ªç¯å®Œæˆï¼Œå…±æ‰§è¡Œ {recursion_depth} è½®")
                
                # æµå¼è¾“å‡ºæœ€ç»ˆç»“æœ
                for line in final_content.splitlines():
                    yield ("å¨œè¿¦", line)
                
                # ä¿å­˜å¯¹è¯å†å²
                self.messages += [{"role": "user", "content": u}, {"role": "assistant", "content": final_content}]
                self.save_log(u, final_content)
                
                # GRAGè®°å¿†å­˜å‚¨ï¼ˆå¼€å‘è€…æ¨¡å¼ä¸å†™å…¥ï¼‰
                if self.memory_manager and not self.dev_mode:
                    try:
                        await self.memory_manager.add_conversation_memory(u, final_content)
                    except Exception as e:
                        logger.error(f"GRAGè®°å¿†å­˜å‚¨å¤±è´¥: {e}")
                
            except Exception as e:
                print(f"å·¥å…·è°ƒç”¨å¾ªç¯å¤±è´¥: {e}")
                yield ("å¨œè¿¦", f"[MCPå¼‚å¸¸]: {e}")
                return

            return
        except Exception as e:
            import sys, traceback
            traceback.print_exc(file=sys.stderr)
            yield ("å¨œè¿¦", f"[MCPå¼‚å¸¸]: {e}")
            return

    async def get_response(self, prompt: str, temperature: float = 0.7) -> str:
        """ä¸ºæ ‘çŠ¶æ€è€ƒç³»ç»Ÿç­‰æä¾›APIè°ƒç”¨æ¥å£""" # ç»Ÿä¸€æ¥å£
        try:
            response = await self.async_client.chat.completions.create(
                model=DEEPSEEK_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=MAX_TOKENS
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"

async def process_user_message(s,msg):
    if VOICE_ENABLED and not msg: #æ— æ–‡æœ¬è¾“å…¥æ—¶å¯åŠ¨è¯­éŸ³è¯†åˆ«
        async for text in s.voice.stt_stream():
            if text:
                msg=text
                break
        return await s.process(msg, is_voice_input=True)  # è¯­éŸ³è¾“å…¥
    return await s.process(msg, is_voice_input=False)  # æ–‡å­—è¾“å…¥

async def send_ai_message(s, msg):
    # å¯ç”¨è¯­éŸ³æ—¶ï¼Œé€šè¿‡WebSocketæµå¼æ¨é€åˆ°voice/genVoiceæœåŠ¡
    if config.VOICE_ENABLED:
        ws_url = f"ws://127.0.0.1:{config.TTS_PORT}/genVoice"  # WebSocketæœåŠ¡åœ°å€
        try:
            async with websockets.connect(ws_url) as websocket:
                await websocket.send(msg)  # å‘é€æ–‡æœ¬åˆ°TTSæœåŠ¡
                while True:
                    response = await websocket.recv()  # æ¥æ”¶éŸ³é¢‘æµï¼ˆjsonï¼‰
                    data = json.loads(response)
                    # dataç»“æ„: {"seq":..., "text":..., "wav_base64":..., "duration":...}
                    # è¿™é‡Œå¯ä»¥æ¨é€dataåˆ°å‰ç«¯æˆ–æœ¬åœ°æ’­æ”¾å™¨
                    print(f"æ”¶åˆ°éŸ³é¢‘ç‰‡æ®µ: åºå·{data['seq']}ï¼Œæ—¶é•¿{data['duration']}ç§’")  # ç¤ºä¾‹ï¼šæ‰“å°ä¿¡æ¯
                    # å¦‚éœ€æµå¼è¿”å›ï¼Œå¯ yield data
                    # å¯æ ¹æ®éœ€æ±‚breakæˆ–ç»§ç»­æ¥æ”¶
        except Exception as e:
            print(f"WebSocket TTSæœåŠ¡è°ƒç”¨å¼‚å¸¸: {e}")
    return msg  # å§‹ç»ˆè¿”å›æ–‡æœ¬
